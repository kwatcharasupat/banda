hydra:
  run:
    dir: outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num}
  launcher:
    _target_: hydra._internal.core_plugins.basic_launcher.BasicLauncher
  sweeper:
    _target_: hydra._internal.core_plugins.basic_sweeper.BasicSweeper
    max_batch_size: null
    params: null
  help:
    app_name: ${hydra.job.name}
    header: '${hydra.help.app_name} is powered by Hydra.

      '
    footer: 'Powered by Hydra (https://hydra.cc)

      Use --hydra-help to view Hydra specific help

      '
    template: '${hydra.help.header}

      == Configuration groups ==

      Compose your configuration from those groups (group=option)


      $APP_CONFIG_GROUPS


      == Config ==

      Override anything in the config (foo.bar=value)


      $CONFIG


      ${hydra.help.footer}

      '
  hydra_help:
    template: 'Hydra (${hydra.runtime.version})

      See https://hydra.cc for more info.


      == Flags ==

      $FLAGS_HELP


      == Configuration groups ==

      Compose your configuration from those groups (For example, append hydra/job_logging=disabled
      to command line)


      $HYDRA_CONFIG_GROUPS


      Use ''--cfg hydra'' to Show the Hydra config.

      '
    hydra_help: ???
  hydra_logging:
    version: 1
    formatters:
      simple:
        format: '[%(asctime)s][HYDRA] %(message)s'
    handlers:
      console:
        class: logging.StreamHandler
        formatter: simple
        stream: ext://sys.stdout
    root:
      level: INFO
      handlers:
      - console
    loggers:
      logging_example:
        level: DEBUG
    disable_existing_loggers: false
  job_logging:
    version: 1
    formatters:
      simple:
        format: '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'
    handlers:
      console:
        class: logging.StreamHandler
        formatter: simple
        stream: ext://sys.stdout
      file:
        class: logging.FileHandler
        formatter: simple
        filename: ${hydra.runtime.output_dir}/${hydra.job.name}.log
    root:
      level: INFO
      handlers:
      - console
      - file
    disable_existing_loggers: false
  env: {}
  mode: MULTIRUN
  searchpath: []
  callbacks: {}
  output_subdir: .hydra
  overrides:
    hydra:
    - hydra.mode=MULTIRUN
    task: []
  job:
    name: train
    chdir: false
    override_dirname: ''
    id: ???
    num: ???
    config_name: config
    env_set: {}
    env_copy: []
    config:
      override_dirname:
        kv_sep: '='
        item_sep: ','
        exclude_keys: []
  runtime:
    version: 1.3.2
    version_base: '1.3'
    cwd: /Users/kwatcharasupat/personal/banda
    config_sources:
    - path: hydra.conf
      schema: pkg
      provider: hydra
    - path: /Users/kwatcharasupat/personal/banda/src/banda/configs
      schema: file
      provider: main
    - path: ''
      schema: structured
      provider: schema
    output_dir: ???
    choices:
      experiment: test_run_3_bandit_music32_lstm
      logger: wandb
      trainer: default
      data: musdb18hq
      model: bandit
      model/mask_estim: mask_estim_default
      model/tfmodel: tfmodel_rnn_lstm
      model/bandsplit: bandsplit_music_32
      model/stft: stft_config
      hydra/env: default
      hydra/callbacks: null
      hydra/job_logging: default
      hydra/hydra_logging: default
      hydra/hydra_help: default
      hydra/help: default
      hydra/sweeper: basic
      hydra/launcher: basic
      hydra/output: default
  verbose: false
project_root: ${oc.env:PROJECT_ROOT,.}
experiment_name: bandit_musdb18hq_test
seed: 42
log_level: INFO
paths:
  output_dir: ${hydra.run.dir}
  log_dir: ${hydra.run.dir}/logs
  data_dir: ${project_root}/data
data:
  target_: banda.data.datamodule.SourceSeparationDataModule
  batch_size: 2
  num_workers: 0
  pin_memory: false
  train_dataset_config:
    target_: banda.data.datasets.musdb18hq.MUSDB18HQDataset
    config:
      split: train
      fs: 44100
      premix_transform:
        target_: banda.data.samplers.random_chunk.RandomChunkingTransform
        chunk_size_seconds: 0.5
        fs: 44100
      dataset_connector:
        target_: banda.data.datasets.musdb18hq.MUSDB18Connector
        config:
          split: train
          data_root: ${oc.env:MUSDB18HQ_DATA_ROOT,${project_root}/data/musdb18hq/intermediates/npz}
  val_dataset_config:
    target_: banda.data.datasets.musdb18hq.MUSDB18HQDataset
    config:
      split: val
      fs: 44100
      premix_transform:
        target_: banda.data.samplers.random_chunk.RandomChunkingTransform
        chunk_size_seconds: 0.5
        fs: 44100
      dataset_connector:
        target_: banda.data.datasets.musdb18hq.MUSDB18Connector
        config:
          split: val
          data_root: ${oc.env:MUSDB18HQ_DATA_ROOT,${project_root}/data/musdb18hq/intermediates/npz}
  test_dataset_config:
    target_: banda.data.datasets.musdb18hq.MUSDB18HQDataset
    config:
      split: test
      fs: 44100
      premix_transform:
        target_: banda.data.samplers.random_chunk.RandomChunkingTransform
        chunk_size_seconds: 3.0
        fs: 44100
      dataset_connector:
        target_: banda.data.datasets.musdb18hq.MUSDB18Connector
        config:
          split: test
          data_root: ${oc.env:MUSDB18HQ_DATA_ROOT,${project_root}/data/musdb18hq/intermediates/npz}
trainer:
  _target_: pytorch_lightning.Trainer
  max_epochs: 1
  accelerator: auto
  devices: auto
  log_every_n_steps: 1
  limit_train_batches: 5
  limit_val_batches: 5
  gradient_clip_val: 5.0
  gradient_clip_algorithm: norm
loss:
  _target_: banda.losses.separation_loss_handler.SeparationLossHandler
  loss_config:
    _target_: banda.losses.loss_configs.LossCollectionConfig
    losses:
      stft_loss:
        fn:
          _target_: banda.losses.multi_resolution_l1_snr.MultiResolutionSTFTLoss
          n_ffts:
          - 2048
          - 512
          hop_lengths:
          - 512
          - 128
          win_lengths:
          - 2048
          - 512
        weight: 1.0
      time_loss:
        fn:
          _target_: banda.losses.time_domain_loss.TimeDomainLoss
        weight: 0.5
      l1_loss:
        fn:
          _target_: torch.nn.L1Loss
        weight: 0.1
      l2_loss:
        fn:
          _target_: torch.nn.MSELoss
        weight: 0.1
      l1_snr_loss:
        fn:
          _target_: banda.losses.coda_losses.L1SNRLoss
        weight: 0.1
      decibel_match_loss:
        fn:
          _target_: banda.losses.coda_losses.DecibelMatchLoss
        weight: 0.1
      l1_snr_decibel_match_loss:
        fn:
          _target_: banda.losses.coda_losses.L1SNRDecibelMatchLoss
        weight: 0.1
metrics:
  _target_: torchmetrics.audio.ScaleInvariantSignalNoiseRatio
inference:
  chunk_size_seconds: 6.0
  hop_size_seconds: 3.0
  fs: 44100
  batch_size: 4
optimizer:
  _target_: torch.optim.Adam
  lr: 0.001
model:
  stft:
    _target_: banda.models.common_components.configs.common_configs.STFTConfig
    n_fft: 2048
    win_length: 2048
    hop_length: 512
    window_fn: hann_window
    wkwargs: null
    power: null
    center: true
    normalized: true
    pad_mode: constant
    onesided: true
  tfmodel:
    _target_: banda.models.common_components.time_frequency_models.tf_models.SeqBandModellingModule
    n_modules: 12
    emb_dim: 128
    rnn_dim: 256
    bidirectional: true
    rnn_type: LSTM
    tf_dropout: 0.0
  mask_estim:
    _target_: banda.models.common_components.configs.common_configs.MaskEstimationConfig
    mask_estimation_type: non_overlapping
    mlp_dim: 512
    hidden_activation: Tanh
    hidden_activation_kwargs: null
    complex_mask: true
    use_freq_weights: false
    in_channel: ${model.input_channels}
_group_:
  _target_: lightning.pytorch.loggers.wandb.WandbLogger
  band_specs:
    _target_: banda.models.common_components.configs.bandsplit_configs.MusicalBandsplitSpecsConfig
    bandsplit_type: musical
    n_bands: 32
  input_channels: 2
  output_channels: 2
  hidden_features: 256
  num_sources: 4
  bandsplit: bandsplit_default
  batch_size: 4
  num_workers: 4
  pin_memory: true
  train_dataset_config:
    _target_: banda.data.datasets.musdb18hq.MUSDB18HQDataset
    config:
      split: train
      dataset_connector:
        _target_: banda.data.datasets.musdb18hq.MUSDB18Connector
        config:
          split: train
          data_root: ${oc.env:DATA_ROOT}/musdb18hq/intermediates/npz
      fs: 44100
      premix_transform:
        _target_: banda.data.augmentations.base.ComposePreMixTransforms
        transforms:
        - _target_: banda.data.samplers.random_chunk.RandomChunkingTransform
          config:
            chunk_size_seconds: 3.0
            fs: 44100
            align_sources: true
      postmix_transform:
        _target_: banda.data.augmentations.base.ComposePostMixTransforms
        transforms:
        - _target_: banda.data.augmentations.time_domain.Gain
          config:
            min_gain_db: -6.0
            max_gain_db: 6.0
        - _target_: banda.data.augmentations.time_domain.NormalizeAudio
          config:
            target_rms_db: -20.0
  val_dataset_config:
    _target_: banda.data.datasets.musdb18hq.MUSDB18HQDataset
    config:
      split: val
      dataset_connector:
        _target_: banda.data.datasets.musdb18hq.MUSDB18Connector
        config:
          split: val
          data_root: ${oc.env:DATA_ROOT}/musdb18hq/intermediates/npz
      fs: 44100
      premix_transform: null
      postmix_transform: null
  max_epochs: 5
  accelerator: auto
  devices: auto
  log_every_n_steps: 50
  project: banda
  name: ${experiment.name}
  save_dir: ${paths.output_dir}
  offline: false
  id: null
  version: null
experiment:
  name: test_run_3_bandit_music32_lstm
