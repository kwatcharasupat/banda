# @package _global_



model:
  _target_: banda.models.core_models.bandit_separator.Bandit
  input_channels: 2
  output_channels: 2
  hidden_features: 256
  num_sources: 4
  bandsplit: bandsplit_music_64_config # Reference the top-level config
  tfmodel: tfmodel_rnn_gru_config # Reference the top-level config
  stft:
    _target_: banda.models.common_components.spectral_components.spectral_base.SpectralComponent
    n_fft: 2048
    hop_length: 512
    win_length: 2048
    window: hann
    return_complex: true

bandsplit_music_64_config:
  _target_: banda.models.common_components.spectral_components.bandsplit.BandsplitModule
  config: # Pass a BandsplitModuleConfig object
    _target_: banda.models.common_components.configs.common_configs.BandsplitModuleConfig
    band_specs:
      _target_: banda.models.common_components.configs.bandsplit_configs.MusicalBandsplitSpecsConfig
      n_bands: 64
      # min_freq: 21.53 # Reverted min_freq to allow default calculation
      # max_freq: 20000 # Reverted max_freq to allow default calculation
      band_scale: linear
      drop_dc_band: true
    n_fft: ${model.stft.n_fft} # Reference n_fft from the stft config
    fs: ${data.samplerate} # Reference fs from the data config
    drop_dc_band: true # Default value
    require_no_overlap: false # Default value

tfmodel_rnn_gru_config:
  _target_: banda.models.common_components.time_frequency_models.tf_models.RNNTFModel
  rnn_type: gru
  n_modules: 2
  hidden_features: 512
  dropout: 0.1
  bidirectional: true
  emb_dim: 64 # Assuming emb_dim should match n_bands for this test

data:
  _target_: banda.data.datamodules.musdb18hq_datamodule.MUSDB18HQDataModule
  data_root: ${paths.data_root}
  stems: ["vocals", "drums", "bass", "other"]
  samplerate: 44100
  segment_duration: 6.0
  num_workers: 8
  batch_size: 16
  pin_memory: True
  train_subset: "train"
  val_subset: "test"
  test_subset: "test"
  train_dataset_config:
    _target_: banda.data.datasets.musdb18hq.MUSDB18HQDataset
    config:
      split: train
      dataset_connector:
        _target_: banda.data.datasets.musdb18hq.MUSDB18Connector
        config:
          split: train
          data_root: "${paths.data_root}/musdb18hq/intermediates/npz"
      fs: 44100
      premix_transform:
        _target_: banda.data.augmentations.base.ComposePreMixTransforms
        transforms:
        - _target_: banda.data.samplers.random_chunk.RandomChunkingTransform
          config:
            chunk_size_seconds: 3.0
            fs: 44100
            align_sources: true
      postmix_transform:
        _target_: banda.data.augmentations.base.ComposePostMixTransforms
        transforms:
        - _target_: banda.data.augmentations.time_domain.Gain
          config:
            min_gain_db: -6.0
            max_gain_db: 6.0
        - _target_: banda.data.augmentations.time_domain.NormalizeAudio
          config:
            target_rms_db: -20.0
  val_dataset_config:
    _target_: banda.data.datasets.musdb18hq.MUSDB18HQDataset
    config:
      split: val
      dataset_connector:
        _target_: banda.data.datasets.musdb18hq.MUSDB18Connector
        config:
          split: val
          data_root: "${paths.data_root}/musdb18hq/intermediates/npz"
      fs: 44100
      premix_transform: null
      postmix_transform: null

loss:
  _target_: banda.losses.separation_loss_handler.SeparationLossHandler
  loss_fn:
    _target_: banda.losses.multi_resolution_l1_snr.MultiResolutionSTFTLoss
    n_ffts: [2048, 512]
    hop_lengths: [512, 128]
    win_lengths: [2048, 512]
    mag_weight: 1.0
    phase_weight: 0.0
    log_scale: False

metrics:
  _target_: torchmetrics.audio.ScaleInvariantSignalNoiseRatio

optimizer:
  _target_: torch.optim.Adam
  lr: 0.001

trainer:
  _target_: pytorch_lightning.Trainer
  max_epochs: 5 # For quick test runs
  accelerator: "auto" # or "gpu", "cpu"
  devices: "auto" # or [0, 1], 1
  log_every_n_steps: 50

experiment:
  name: "test_run_2_bandit_music64_rnn"