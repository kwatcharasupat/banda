# @package _global_
defaults:
  - /logger: wandb
  - _self_

model:
  _target_: banda.models.core_models.banquet_separator.Banquet
  input_channels: 2
  tfmodel:
    _target_: banda.models.common_components.time_frequency_models.tf_models.SeqBandModellingModule
    n_modules: 12
    emb_dim: 128
    rnn_dim: 256
    bidirectional: True
    rnn_type: "GRU"
    dropout: 0.0 # Renamed from tf_dropout
  stft:
    _target_: banda.models.common_components.configs.common_configs.STFTConfig
    n_fft: 2048
    win_length: 2048
    hop_length: 512
    window_fn: "hann_window"
    wkwargs: null
    power: null
    center: True
    normalized: True
    pad_mode: "constant"
    onesided: True
  mask_estim:
    _target_: banda.models.common_components.configs.common_configs.MaskEstimationConfig
    mask_estimation_type: overlapping # Changed from non_overlapping to overlapping
    mlp_dim: 512
    hidden_activation: "Tanh"
    hidden_activation_kwargs: null
    complex_mask: True
    use_freq_weights: False
    in_channel: ${model.input_channels}
    norm_mlp_cls: banda.models.common_components.mask_estimation.mask_estimation_modules.NormMLP
  bandsplit:
    _target_: banda.models.common_components.configs.common_configs.BandsplitModuleConfig
    band_specs:
      _target_: banda.models.common_components.configs.bandsplit_configs.MusicalBandsplitSpecsConfig # Corrected _target_ path
      bandsplit_type: music
      n_bands: 32
    require_no_overlap: False
    require_no_gap: True
    normalize_channel_independently: False
    treat_channel_as_feature: False

data:
  batch_size: 4
  num_workers: 0
  pin_memory: false
  query_features: class_label
  train_dataset_config:
    _target_: banda.data.datasets.musdb18hq.MUSDB18HQDataset
    config:
      split: train
      dataset_connector:
        _target_: banda.data.datasets.musdb18hq.MUSDB18Connector
        config:
          split: train
          data_root: "${paths.data_root}/musdb18hq/intermediates/npz"
      fs: 44100
      premix_transform:
        _target_: banda.data.augmentations.base.ComposePreMixTransforms
        transforms:
        - _target_: banda.data.samplers.random_chunk.RandomChunkingTransform
          config:
            chunk_size_seconds: 3.0
            fs: 44100
            align_sources: true
      postmix_transform:
        _target_: banda.data.augmentations.base.ComposePostMixTransforms
        transforms:
        - _target_: banda.data.augmentations.time_domain.Gain
          config:
            min_gain_db: -6.0
            max_gain_db: 6.0
        - _target_: banda.data.augmentations.time_domain.NormalizeAudio
          config:
            target_rms_db: -20.0

  val_dataset_config:
    _target_: banda.data.datasets.musdb18hq.MUSDB18HQDataset
    config:
      split: val
      dataset_connector:
        _target_: banda.data.datasets.musdb18hq.MUSDB18Connector
        config:
          split: val
          data_root: "${paths.data_root}/musdb18hq/intermediates/npz"
      fs: 44100
      premix_transform:
        _target_: banda.data.augmentations.base.ComposePreMixTransforms
        transforms:
        - _target_: banda.data.samplers.random_chunk.RandomChunkingTransform
          config:
            chunk_size_seconds: 3.0
            fs: 44100
            align_sources: true
      postmix_transform: null
loss:
  _target_: banda.losses.separation_loss_handler.SeparationLossHandler
  loss_config:
    losses:
      multi_resolution_stft_loss:
        fn:
          class_target: banda.losses.multi_resolution_l1_snr.MultiResolutionSTFTLoss
          n_ffts: [2048, 512]
          hop_lengths: [512, 128]
          win_lengths: [2048, 512]
        weight: 1.0


metrics:
  _target_: torchmetrics.audio.ScaleInvariantSignalNoiseRatio

optimizer:
  _target_: torch.optim.Adam
  lr: 0.001

trainer:
  _target_: pytorch_lightning.Trainer
  max_epochs: 5
  accelerator: "auto"
  devices: "auto"
  log_every_n_steps: 50

name: test_run_7_banquet_music32_query_gru