---------------------------------------
Begin Slurm Prolog: Sep-05-2025 22:56:40
Job ID:    2910588
User ID:   kwatchar3
Account:   ece
Job name:  bandit-musdb18hq-nodbm.sbatch
Partition: pace-cpu
QOS:       pace-ice
---------------------------------------
/home/hice1/kwatchar3/.conda/envs/banda/lib/python3.12/site-packages/hydra/_internal/config_loader_impl.py:216: UserWarning: provider=hydra.searchpath in main, path=/home/kwatchar3/projects/banda/configs is not available.
  warnings.warn(
2025-09-05 22:57:34 [info     ] Config:                        config={'model': {'cls': 'FixedStemBandit', 'params': {'spectrogram': {'n_fft': 2048, 'hop_length': 512, 'win_length': 2048, 'window': 'hann', 'fs': 44100}, 'normalization': {'eps': 1e-06, 'dbrms_threshold': -60}, 'bandsplit': {'n_bands': 64, 'in_channels': 2, 'emb_dim': 128}, 'tf_model': {'n_modules': 8, 'rnn_type': 'GRU', 'emb_dim': '${..bandsplit.emb_dim}', 'rnn_dim': 256, 'bidirectional': True}, 'mask_estim': {'emb_dim': '${..bandsplit.emb_dim}', 'mlp_dim': 512, 'in_channels': '${..bandsplit.in_channels}'}, 'stems': ['vocals', 'drums', 'bass', 'other'], 'max_simultaneous_stems': 4}}, 'data': {'train': {'datasource': [{'cls': 'MUSDB18HQDatasource', 'params': {'split': 'train'}}], 'dataset': {'cls': 'RandomChunkDataset', 'params': {'n_channels': 2, 'fs': 44100, 'chunk_size_seconds': 6.0, 'allow_autolooping': True, 'max_dataset_size': 8192, 'premix_augmentation': {'augmentations': [{'cls': 'Gain', 'params': {'min_gain_db': -6, 'max_gain_db': 6.0, 'p': 1.0}}, {'cls': 'PolarityInversion', 'params': {'p': 0.5}}]}}}, 'dataloader': {'batch_size': 8, 'num_workers': 16, 'shuffle': True, 'drop_last': False, 'pin_memory': True, 'prefetch_factor': 4}}, 'val': {'datasource': [{'cls': 'MUSDB18HQDatasource', 'params': {'split': 'val', 'load_duration': True}}], 'dataset': {'cls': 'DeterministicChunkDataset', 'params': {'n_channels': 2, 'fs': 44100, 'chunk_size_seconds': 6.0, 'hop_size_seconds': 6.0, 'allow_autolooping': False, 'max_dataset_size': 1024}}, 'dataloader': {'batch_size': 8, 'num_workers': 16, 'shuffle': False, 'drop_last': False, 'pin_memory': True}}, 'test': {'datasource': [{'cls': 'MUSDB18HQDatasource', 'params': {'split': 'test'}}], 'dataset': {'cls': 'FullTrackDataset', 'params': {'n_channels': 2, 'fs': 44100, 'allow_autolooping': False}}, 'dataloader': {'batch_size': 8, 'num_workers': 4, 'shuffle': True, 'drop_last': False, 'pin_memory': True}}}, 'logger': {}, 'loss': {'losses': [{'cls': 'L1SNRLoss', 'name': 'l1snr-time', 'weight': 1.0, 'params': {'domain': 'audio', 'eps': 0.001}}, {'cls': 'L1SNRLoss', 'name': 'l1snr-tf', 'weight': 1.0, 'params': {'domain': 'spectrogram', 'eps': 0.001}}]}, 'metrics': {'metrics': [{'cls': 'SignalNoiseRatio', 'params': {}}, {'cls': 'PredDecibel', 'params': {}}, {'cls': 'TargetDecibel', 'params': {}}], 'stems': '${..model.params.stems}'}, 'optimizer': {'optimizer': {'cls': 'Adam', 'params': {'lr': 0.001, 'weight_decay': 0.0, 'fused': True}}, 'scheduler': {'cls': 'StepLR', 'params': {'step_size': 2, 'gamma': 0.98}}}, 'trainer': {'gradient_clip_val': 2.0, 'max_epochs': 100}, 'seed': 42}
[rank: 0] Seed set to 42
/home/hice1/kwatchar3/.conda/envs/banda/lib/python3.12/site-packages/torchmetrics/utilities/prints.py:62: FutureWarning: Importing `SignalNoiseRatio` from `torchmetrics` was deprecated and will be removed in 2.0. Import `SignalNoiseRatio` from `torchmetrics.audio` instead.
  _future_warning(
Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
wandb: Currently logged in as: kwatcharasupat (kwatcharasupat-gatech) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: creating run
wandb: Tracking run with wandb version 0.21.3
wandb: Run data is saved locally in ./wandb/run-20250905_225746-275ys0br
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-glitter-766
wandb: ‚≠êÔ∏è View project at https://wandb.ai/kwatcharasupat-gatech/banda
wandb: üöÄ View run at https://wandb.ai/kwatcharasupat-gatech/banda/runs/275ys0br

  | Name                             | Type                      | Params | Mode 
---------------------------------------------------------------------------------------
0 | model                            | FixedStemBandit           | 64.0 M | train
1 | model.normalizer                 | Normalizer                | 0      | train
2 | model.stft                       | Spectrogram               | 0      | train
3 | model.bandsplit                  | BandSplitModule           | 1.1 M  | train
4 | model.tf_model                   | RNNSeqBandModellingModule | 10.5 M | train
5 | model.mask_estim                 | ModuleDict                | 52.3 M | train
6 | loss_handler                     | LossHandler               | 0      | train
7 | loss_handler.losses              | ModuleDict                | 0      | train
8 | metric_handler                   | MetricHandler             | 0      | train
9 | metric_handler.metric_collection | ModuleDict                | 0      | train
---------------------------------------------------------------------------------------
64.0 M    Trainable params
0         Non-trainable params
64.0 M    Total params
256.039   Total estimated model params size (MB)
4456      Modules in train mode
0         Modules in eval mode
SLURM auto-requeueing enabled. Setting signal handlers.
Sanity Checking: |          | 0/? [00:00<?, ?it/s]2025-09-05 22:57:50 [info     ] Creating dataloader with config: datasource=[DatasourceConfig(cls='MUSDB18HQDatasource', params=DatasourceParams(split='val', load_duration=True))] dataset=DatasetConfig(cls='DeterministicChunkDataset', params=DatasetParams(n_channels=2, fs=44100, allow_autolooping=False, premix_augmentation=None, variable_sources=False, chunk_size_seconds=6.0, hop_size_seconds=6.0, max_dataset_size=1024)) dataloader=DataLoaderConfig(batch_size=8, shuffle=False, num_workers=16, pin_memory=True, drop_last=False)
2025-09-05 22:57:50 [info     ] Loading tracks for MUSDB18HQ with config={'split': 'val', 'load_duration': True}
2025-09-05 22:57:54 [warning  ] Max dataset size is set. This may automatically increase hop size if the total number of chunks exceeds 1024.
/home/hice1/kwatchar3/.conda/envs/banda/lib/python3.12/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Error executing job with overrides: []
Traceback (most recent call last):
  File "/home/hice1/kwatchar3/.conda/envs/banda/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1243, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hice1/kwatchar3/.conda/envs/banda/lib/python3.12/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
           ^^^^^^^^^^^^^^^^^^^
  File "/home/hice1/kwatchar3/.conda/envs/banda/lib/python3.12/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
           ^^^^^^^^^^^^^^^^^^^
  File "/home/hice1/kwatchar3/.conda/envs/banda/lib/python3.12/multiprocessing/connection.py", line 440, in _poll
    r = wait([self], timeout)
        ^^^^^^^^^^^^^^^^^^^^^
  File "/home/hice1/kwatchar3/.conda/envs/banda/lib/python3.12/multiprocessing/connection.py", line 1136, in wait
    ready = selector.select(timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hice1/kwatchar3/.conda/envs/banda/lib/python3.12/selectors.py", line 415, in select
    fd_event_list = self._selector.poll(timeout)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hice1/kwatchar3/.conda/envs/banda/lib/python3.12/site-packages/torch/utils/data/_utils/signal_handling.py", line 73, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 4140460) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/storage/ice1/4/1/kwatchar3/banda/scripts/train.py", line 93, in <module>
    train()
  File "/home/hice1/kwatchar3/.conda/envs/banda/lib/python3.12/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/home/hice1/kwatchar3/.conda/envs/banda/lib/python3.12/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/home/hice1/kwatchar3/.conda/envs/banda/lib/python3.12/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/home/hice1/kwatchar3/.conda/envs/banda/lib/python3.12/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
    raise ex
  File "/home/hice1/kwatchar3/.conda/envs/banda/lib/python3.12/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           ^^^^^^
  File "/home/hice1/kwatchar3/.conda/envs/banda/lib/python3.12/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            ^^^^^^^^^^
  File "/home/hice1/kwatchar3/.conda/envs/banda/lib/python3.12/site-packages/hydra/_internal/hydra.py", line 132, in run
    _ = ret.return_value
        ^^^^^^^^^^^^^^^^
  File "/home/hice1/kwatchar3/.conda/envs/banda/lib/python3.12/site-packages/hydra/core/utils.py", line 260, in return_value
    raise self._return_value
  File "/home/hice1/kwatchar3/.conda/envs/banda/lib/python3.12/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
                       ^^^^^^^^^^^^^^^^^^^^^^^
  File "/storage/ice1/4/1/kwatchar3/banda/scripts/train.py", line 90, in train
    trainer.fit(system, datamodule=datamodule, ckpt_path=config.ckpt_path)
  File "/home/hice1/kwatchar3/.conda/envs/banda/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 560, in fit
    call._call_and_handle_interrupt(
  File "/home/hice1/kwatchar3/.conda/envs/banda/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 49, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hice1/kwatchar3/.conda/envs/banda/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 598, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/home/hice1/kwatchar3/.conda/envs/banda/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1011, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/home/hice1/kwatchar3/.conda/envs/banda/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1053, in _run_stage
    self._run_sanity_check()
  File "/home/hice1/kwatchar3/.conda/envs/banda/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1082, in _run_sanity_check
    val_loop.run()
  File "/home/hice1/kwatchar3/.conda/envs/banda/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hice1/kwatchar3/.conda/envs/banda/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 138, in run
    batch, batch_idx, dataloader_idx = next(data_fetcher)
                                       ^^^^^^^^^^^^^^^^^^
  File "/home/hice1/kwatchar3/.conda/envs/banda/lib/python3.12/site-packages/pytorch_lightning/loops/fetchers.py", line 134, in __next__
    batch = super().__next__()
            ^^^^^^^^^^^^^^^^^^
  File "/home/hice1/kwatchar3/.conda/envs/banda/lib/python3.12/site-packages/pytorch_lightning/loops/fetchers.py", line 61, in __next__
    batch = next(self.iterator)
            ^^^^^^^^^^^^^^^^^^^
  File "/home/hice1/kwatchar3/.conda/envs/banda/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py", line 341, in __next__
    out = next(self._iterator)
          ^^^^^^^^^^^^^^^^^^^^
  File "/home/hice1/kwatchar3/.conda/envs/banda/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py", line 142, in __next__
    out = next(self.iterators[0])
          ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/hice1/kwatchar3/.conda/envs/banda/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/home/hice1/kwatchar3/.conda/envs/banda/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1448, in _next_data
    idx, data = self._get_data()
                ^^^^^^^^^^^^^^^^
  File "/home/hice1/kwatchar3/.conda/envs/banda/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1412, in _get_data
    success, data = self._try_get_data()
                    ^^^^^^^^^^^^^^^^^^^^
  File "/home/hice1/kwatchar3/.conda/envs/banda/lib/python3.12/site-packages/torch/utils/data/dataloader.py", line 1256, in _try_get_data
    raise RuntimeError(
RuntimeError: DataLoader worker (pid(s) 4140460) exited unexpectedly
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mfresh-glitter-766[0m at: [34mhttps://wandb.ai/kwatcharasupat-gatech/banda/runs/275ys0br[0m
slurmstepd: error: Detected 1 oom_kill event in StepId=2910588.0. Some of the step tasks have been OOM Killed.
srun: error: atl1-1-02-012-5-1: task 0: Out Of Memory
---------------------------------------
Begin Slurm Epilog: Sep-05-2025 22:58:05
Job ID:        2910588
User ID:       kwatchar3
Account:       ece
Job name:      bandit-musdb18hq-nodbm.sbatch
Resources:     cpu=1,mem=4G,node=1
Rsrc Used:     cput=00:01:25,vmem=0,walltime=00:01:25,mem=19780K,energy_used=0
Partition:     pace-cpu
QOS:           pace-ice
Nodes:         atl1-1-02-012-5-1
---------------------------------------
