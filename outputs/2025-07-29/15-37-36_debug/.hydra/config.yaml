model:
  _target_: banda.models.separator.Separator
  stems:
  - vocals
  - bass
  - drums
  - other
  fs: 44100
  emb_dim: 128
  in_channel: 2
  stft:
    _target_: banda.models.configs.STFTConfig
    n_fft: 2048
    win_length: 2048
    hop_length: 512
    window_fn: hann_window
    wkwargs: null
    power: null
    center: true
    normalized: true
    pad_mode: constant
    onesided: true
  bandsplit:
    _target_: banda.models.configs.BandsplitModuleConfig
    band_specs:
      _target_: banda.models.spectral.get_bandsplit_specs_factory
      bandsplit_type: musical
      n_bands: 64
    require_no_overlap: false
    require_no_gap: true
    normalize_channel_independently: false
    treat_channel_as_feature: true
  tfmodel:
    _target_: banda.models.configs.TFModelConfig
    tf_model_type: rnn
    n_tf_modules: 12
    rnn_dim: 256
    bidirectional: true
    rnn_type: GRU
    tf_dropout: 0.0
  mask_estim:
    _target_: banda.models.configs.MaskEstimationConfig
    mlp_dim: 512
    hidden_activation: Tanh
    hidden_activation_kwargs: null
    complex_mask: true
    use_freq_weights: false
project_root: ${oc.env:PROJECT_ROOT,.}
experiment_name: debug_run
seed: 42
log_level: DEBUG
paths:
  output_dir: ${hydra.run.dir}
  log_dir: ${hydra.run.dir}/logs
  data_dir: ${project_root}/data
data:
  target_: banda.data.datamodule.SourceSeparationDataModule
  batch_size: 1
  num_workers: 0
  pin_memory: false
  train_dataset_config:
    target_: banda.data.datasets.musdb18hq.MUSDB18HQDataset
    config:
      split: train
      fs: 44100
      premix_transform:
        target_: banda.data.samplers.random_chunk.RandomChunkingTransform
        chunk_size_seconds: 1.0
        fs: 44100
      dataset_connector:
        target_: banda.data.datasets.musdb18hq.MUSDB18Connector
        config:
          split: train
          data_root: ${oc.env:DATA_ROOT}/musdb18hq/intermediates/npz
  val_dataset_config:
    target_: banda.data.datasets.musdb18hq.MUSDB18HQDataset
    config:
      split: val
      fs: 44100
      premix_transform:
        target_: banda.data.samplers.random_chunk.RandomChunkingTransform
        chunk_size_seconds: 1.0
        fs: 44100
      dataset_connector:
        target_: banda.data.datasets.musdb18hq.MUSDB18Connector
        config:
          split: val
          data_root: ${oc.env:DATA_ROOT}/musdb18hq/intermediates/npz
  test_dataset_config:
    target_: banda.data.datasets.musdb18hq.MUSDB18HQDataset
    config:
      split: test
      fs: 44100
      premix_transform:
        target_: banda.data.samplers.random_chunk.RandomChunkingTransform
        chunk_size_seconds: 1.0
        fs: 44100
      dataset_connector:
        target_: banda.data.datasets.musdb18hq.MUSDB18Connector
        config:
          split: test
          data_root: ${oc.env:DATA_ROOT}/musdb18hq/intermediates/npz
trainer:
  target_: pytorch_lightning.Trainer
  max_epochs: 5
  accelerator: auto
  devices: auto
  log_every_n_steps: 1
loss:
  target_: banda.losses.separation_loss_handler.SeparationLossHandler
  loss_fn:
    _target_: banda.losses.multi_resolution_l1_snr.MultiResolutionSTFTLoss
    n_ffts:
    - 2048
    - 512
    hop_lengths:
    - 512
    - 128
    win_lengths:
    - 2048
    - 512
    p: 1.0
    scale_invariant: false
    take_log: true
    reduction: mean
    eps: 1.0e-08
metrics:
  _target_: torchmetrics.audio.ScaleInvariantSignalNoiseRatio
inference:
  chunk_size_seconds: 1.0
  hop_size_seconds: 0.5
  fs: 44100
  batch_size: 1
optimizer:
  _target_: torch.optim.Adam
  lr: 0.001
